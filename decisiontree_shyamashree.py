# -*- coding: utf-8 -*-
"""DecisionTree_Shyamashree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FtcC5CTQgla7yoPyd0NXjQeGK-uTkxPr
"""

'''
Q1. Describe the decision tree classifier algorithm and how it works to make predictions.
Ans.
Decision tree follows a tree-like structure. There is a root node, internal nodes, decision branches and leaf nodes.
It can solve both classification and regression problem.
1) Root node: It is the initial node,where the entire dataset starts to split.
2) Decision branch: It mainly represnts dicision or conditins in the feature.
3) internal node: It represents the internal nodes of the tree
4) leaf node: It represents the end layer of the tree.
'''
'''
Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.
Ans.
1) Entropy: It measures the  impurity. It helps to find out the best split for building a decision tree.
entropy = -summation(pi*log2(pi)),i=1,2,...,n, where pi = probability of randomly selected an example in class i
2) Gini Index: It measure impurity in the dataset. It is calculated by summing the square probabilities of each class.
gini index = 1 - summation(pi)^2
3) Information Gain: It represents how much information is gained by spilting a set of data on a particular feature.
'''
'''
Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.
Ans.
Each root node is split into several nodes. The key idea is to use a decision tree to partition the
data space into dense regions and sparse regions. The splitting of a binary tree can either be binary or multiway. The
algorithm keeps on splitting the tree until the data is sufficiently homogeneous
'''
'''
Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make
predictions.
Ans.
When we split the dataset every decision node or internal node creates hyperplane.
All the hyperplane are parallel to either X-axis or Y-axis.
It actually hepls to measure to informativeness of the features.

'''
'''
Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a
classification model.
Ans.
It is a table containing the values  true positives, true negatives, false positives, and false negatives.
It helps to evaluate the performance of the model by identifing the correct and incorrect predictions.
'''
'''
Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be
calculated from it.
Ans.
Tp = 10, TN=20,FP=30,FN=12
Precision = TP/(TP+FP)
Recall = TP/(TP+FN)
F1-Score = 2/(1/precision + 1/Recall)
'''
'''
Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and
explain how this can be done.
Ans.
The simplest metric for model evaluation is Accuracy.It represents the ratio of the correct predictions
to the total number of predictions.
Accuracy is useful when the target class is well balanced but is not a good choice with unbalanced classes

'''
'''
Q8. Provide an example of a classification problem where precision is the most important metric, and
explain why.
Ans.
In spam mail detection, it is okay if any spam mail remains undetected (false negative), but what
if we miss any critical mail because it is classified as spam (false positive). In this situation, False
Positive should be as low as possible. Here, precision is more vital as compared to recall.
'''
'''
Q9. Provide an example of a classification problem where recall is the most important metric, and explain
why.
Ans.
In most high-risk disease detection cases (like cancer), recall is a more important evaluation metric than
precision. However, precision is more useful when we want to affirm the correctness of our model.
'''