{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.What is the difference between a list and a tuple in Python?"
      ],
      "metadata": {
        "id": "HR-SBargnFUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "i) List is mutable(i.e, after creating a list, elements can be changed).\n",
        "Tuple is immutable(i.e, after creating a tuple, elements can not be changed).\n",
        "ii) List is better for performing the operations, such as insertion, deletion.\n",
        "Tuple is appropriate for accessing the elements.\n",
        "iii) List consume more memory.\n",
        "Tuple consume more memory as compared to the list.\n",
        "iv) Lists have several built-in methods.\n",
        "Tuples does not have many built-in methods.\n",
        "v) Example of list is [1,5,9,3].\n",
        "Example of tuple is (5,9,2)\n",
        "'''"
      ],
      "metadata": {
        "id": "pdoN9zqHnDWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.How can you iterate through a list in Python?"
      ],
      "metadata": {
        "id": "2_Qjqpv-yqcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#i)First method:\n",
        "#using for loop we can iterate through a list\n",
        "List1 = [2,8,3,1]\n",
        "for element in List1:\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHAHkVcVnDZg",
        "outputId": "9f66a58a-a290-484f-8b6d-8b0c66eb7f89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "8\n",
            "3\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iii)Second method:\n",
        "#using list comprehension we can iterate through a list\n",
        "List3 = ['apple','banana','mango']\n",
        "elements = [print(i) for i in List3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzPUYxqJoAv2",
        "outputId": "e8750bf5-f698-4de1-ef19-184dd9eb7abd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple\n",
            "banana\n",
            "mango\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iv)Third method\n",
        "#using enumerate() function we can iterate through a list\n",
        "List4 = [8,3,4,6,7]\n",
        "for i,ele in enumerate(List4):\n",
        "  print(i,\",\",ele)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9ncQrzloEfM",
        "outputId": "db29a01d-8d34-4882-deb9-a74e9e07d48c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 , 8\n",
            "1 , 3\n",
            "2 , 4\n",
            "3 , 6\n",
            "4 , 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.How do you handle exceptions in Python?"
      ],
      "metadata": {
        "id": "QL8qTZxQ-Tqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Try and except statements are used to identify and handle the exceptions in python.\n",
        "The statement that can raise the exceptions are kept inside the try clause and the\n",
        "statements that handle the exceptions are written inside except clause.\n",
        "'''\n",
        "#Example:\n",
        "def func(a):\n",
        "  if a > 5:\n",
        "    b = a/(a-7)\n",
        "    print(\"Value of b =\",b)\n",
        "\n",
        "try:\n",
        "   func(7)\n",
        "\n",
        "except ZeroDivisionError:\n",
        "  print(\"ZeroDivisionError Occured and Handled\")\n"
      ],
      "metadata": {
        "id": "GEC9g7ywnDho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c074804-033c-42ef-de20-85c3e2bea097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZeroDivisionError Occured and Handled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.What are list comprehensions in Python?"
      ],
      "metadata": {
        "id": "vzR8vb_T-K31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "A python list comprehension consists of brackets containing the expression, which\n",
        "is executed for each element along with the for loop to iterate over each element\n",
        "in the python list.It is a shorter syntax when we want to create a new list based\n",
        "on the values of an existing list.\n",
        "'''\n",
        "\n",
        "#Example\n",
        "List1 = [1,2,3,4]\n",
        "SquaredList1 = [x**2 for x in List1]\n",
        "print(SquaredList1)"
      ],
      "metadata": {
        "id": "wlP-sXd25ryT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc95b64d-c90b-4709-f5c3-8384c55d4903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What is the purpose of the if __name__ == \"__main__\" statement?"
      ],
      "metadata": {
        "id": "RKVNuOQ5Jk82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Before executing the code, python interpreter reads source file and define few\n",
        "global variables.If the python interpreter is running that module as the main\n",
        "program, it sets special __name__ variable to have a value '__main__'.If this file\n",
        "is being imported from another module,__name__ will be set to the module's name.\n",
        "Module's name is available as value to __name__ global variable.A module is a file\n",
        "containing python definitions and statements.The file name is the module name with\n",
        "suffix.py appended.\n",
        "'''\n",
        "print(\"Always executed\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  print(\"Executed when invoked directly\")\n",
        "else:\n",
        "  print(\"Executed when imported\")"
      ],
      "metadata": {
        "id": "taPm2wlS5r1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7da5deb-2e42-42a6-fc78-04d332b99893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Always executed\n",
            "Executed when invoked directly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.What is the purpose of the with statement in Python?"
      ],
      "metadata": {
        "id": "BktekBj-Rkit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In python with statement is used in exception handling to make the code cleaner\n",
        "and much more readable.\n",
        "'''\n",
        "#Example:\n",
        "#without using with statement\n",
        "file = open(\"file_path\",'w')\n",
        "file.write(\"There are 5 students in the  class. They love to play cricket.\")\n",
        "file.close()\n",
        "# using with statement\n",
        "with open(\"file__path\",'w') as file:\n",
        "  file.write(\"There are 5 students in the  class. They love to play cricket.\")\n",
        "\n",
        "'''\n",
        "We can observe that in case of using with statement, there is no need to\n",
        "call file.close(). In first approach, during the file.write() call can prevent\n",
        "the file from closing properly which may introduce several bugs in the code.\n",
        "But using with statement makes the code compact and much more readable and also\n",
        "helps to avoid bugs.\n",
        "'''"
      ],
      "metadata": {
        "id": "zmE77wJg5r4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What are the key features of Spark?"
      ],
      "metadata": {
        "id": "fUHcyk71ZJcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Key features of Apache Spark:\n",
        "i) Fast Processing: The most important feature of Apache Spark that has made the big data\n",
        "world choose this technology over other is its speed. Big data is characterized by volumn,\n",
        "velocity, variety due to which it needs to be processed at a higher speed.Spark contains\n",
        "Resilient Distributed Datasets(RDDs) that save the time taken in reading and writing\n",
        "operations and hence it runs 10 to 100 times faster than Hadoop.\n",
        "ii) Flexibility: Apache Spark supports multuple languages and allows developer to write\n",
        "applications in python,scala,R,jave.Equipped with over 80 high-level operations, this tool\n",
        "is quite rich from this aspect.\n",
        "iii) In-memory computing: Spark stores data in the RAM of servers which allows it to access\n",
        "data quickly and which in-turn it accelerates the speed of analytics.\n",
        "iv) Real-time processing: Spark is able to process real-time streaming data. Unlike MapReduce,\n",
        "which process the stored data, spark is able to process real-time data and hence able produce\n",
        "instant outcomes.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "gTLRm_xhTyUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What are Resilient Distributed Datasets (RDDs) in Spark?"
      ],
      "metadata": {
        "id": "HZ8p7MF2_cj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Resilient Distributed Datasets(RDDs) are primary data structure in spark. A RDDs is a low\n",
        "level API . It is the collection of objects which is capable of storing the data partitioned\n",
        "across the multiple nodes of the cluster and also allows them to do processing in parallel.\n",
        "RDDs are reliable and memory-efficient when it comes to parallel processing. RDDs make easier\n",
        "to train machine learning algorithms and handle large amounts of data\n",
        "for analytics.\n",
        "'''"
      ],
      "metadata": {
        "id": "69dTpVPHTyXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is the difference between a DataFrame and an RDD in Spark?"
      ],
      "metadata": {
        "id": "JuYZas50Pamq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "i) RDDs is a distributed collection of data elements without any schema.\n",
        "Dataframe is distributed collection organized into the nameed columns.\n",
        "ii) No in-built optimization engine for RDDs. Developers need to write\n",
        "the optimized code themselves.\n",
        "DataFrame uses a catalyst optimizer for optimization.\n",
        "iii) In RDDs , we need to define the schema manually.\n",
        "iv) RDDs is slower than DataFrame to perform simple operations like\n",
        "grouping the data.\n",
        "Dataframe provides an easy API to perform aggregation operations.It performs\n",
        "aggregation faster than RDDs.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "tLrzLzv8Tyae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.What is Spark's ecosystem?"
      ],
      "metadata": {
        "id": "qGESFr6TZJDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Spark's ecosystem comprises the following components:\n",
        "i) Shark(SQL): It is used to perform structured data analysis, specially if the data is too voluminous.\n",
        "ii) Spark Streaming(Streaming):It enables to create analytical and interactive applications for live\n",
        "streaming data.\n",
        "iii) MLLib(Machine Learning):It is a machine learning library, built on the top of spark.It has the\n",
        "provision to support many machine learning algorithms.\n",
        "iv) GraphX(Graph Computation):It is the spark's graph computation engine.\n",
        "v) SparkR(R on Spark):It is a package for R language to enable R users to leverage the power of spark\n",
        "from R shell.\n",
        "vi) BlindDB(Appoximate SQL):If there is a large amount of data barraging and we are not interested in the exact\n",
        "results, just want to have a rough picture, BiindDB gets us the same.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "ZRHciBqSTydV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MXLof5aeTyf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3dwbzSA5sA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}